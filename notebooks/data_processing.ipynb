{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Extraction and Processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Option1 - Already Processed Data (through LinkedIn article)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "enhanced_path = 'data/enhanced'\n",
    "os.makedirs(enhanced_path, exist_ok=True)\n",
    "\n",
    "file_name = \"shakespeare.txt\"\n",
    "if not os.path.isfile(file_name):\n",
    "\turl = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "\tdata = requests.get(url)\n",
    "\n",
    "\twith open(os.path.join(enhanced_path, file_name), 'w') as f:\n",
    "\t\tf.write(data.text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36009 3991\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('data', file_name), 'r') as f:\n",
    "\ttexts = f.readlines()\n",
    "\n",
    "test_portion = 0.1\n",
    "idx = int(len(texts)*(1-test_portion))\n",
    "while not texts[idx] == '\\n':  # test data should start from a valid block (not in the middle of a conversation\n",
    "    idx += 1\n",
    "\n",
    "test_texts = texts[idx:]\n",
    "train_texts = texts[:idx]\n",
    "print(len(train_texts), len(test_texts))\n",
    "\n",
    "with open(os.path.join(enhanced_path, 'test.txt'), 'w') as f:\n",
    "\tf.write(''.join(test_texts))\n",
    "\n",
    "with open(os.path.join(enhanced_path, 'train.txt'), 'w') as f:\n",
    "\tf.write(''.join(train_texts))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Option2 - Manually download raw kagle dataset and process"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 111396 entries, 0 to 111395\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   Dataline          111396 non-null  int64  \n",
      " 1   Play              111396 non-null  object \n",
      " 2   PlayerLinenumber  111393 non-null  float64\n",
      " 3   ActSceneLine      105153 non-null  object \n",
      " 4   Player            111389 non-null  object \n",
      " 5   PlayerLine        111396 non-null  object \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../data/raw/Shakespeare_data.csv')\n",
    "data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111396, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Dataline      Play  PlayerLinenumber ActSceneLine         Player  \\\n2         3  Henry IV               NaN          NaN            NaN   \n3         4  Henry IV               1.0        1.1.1  KING HENRY IV   \n4         5  Henry IV               1.0        1.1.2  KING HENRY IV   \n\n                                          PlayerLine  \n2  Enter KING HENRY, LORD JOHN OF LANCASTER, the ...  \n3             So shaken as we are, so wan with care,  \n4         Find we a time for frighted peace to pant,  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataline</th>\n      <th>Play</th>\n      <th>PlayerLinenumber</th>\n      <th>ActSceneLine</th>\n      <th>Player</th>\n      <th>PlayerLine</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Henry IV</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Enter KING HENRY, LORD JOHN OF LANCASTER, the ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Henry IV</td>\n      <td>1.0</td>\n      <td>1.1.1</td>\n      <td>KING HENRY IV</td>\n      <td>So shaken as we are, so wan with care,</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Henry IV</td>\n      <td>1.0</td>\n      <td>1.1.2</td>\n      <td>KING HENRY IV</td>\n      <td>Find we a time for frighted peace to pant,</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head(5).tail(3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100256, 6) (11140, 6)\n"
     ]
    }
   ],
   "source": [
    "test_portion = 0.1\n",
    "train_acts = int(len(data) * (1 - test_portion))\n",
    "train = data.iloc[:train_acts, :]  # no shuffle\n",
    "test = data.iloc[train_acts:, :]\n",
    "print(train.shape, test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "test.to_csv('../data/test.csv', index=False)\n",
    "train.to_csv('../data/train.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Option3 - Process the raw txt (with tokenizer splits)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "text_data = []\n",
    "data_dir = 'data/raw'\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join(data_dir, filename), 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            text_data.append(text)\n",
    "\n",
    "corpus_text = '\\n'.join(text_data)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenized_text = tokenizer.tokenize(corpus_text)\n",
    "train_text, test_text = train_test_split(tokenized_text, test_size=0.1, random_state=42, shuffle=False)\n",
    "\n",
    "\n",
    "output_dir = 'data/processed'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(output_dir, 'train_data.txt'), 'w', encoding='utf-8') as file:\n",
    "    file.write(tokenizer.convert_tokens_to_string(train_text))\n",
    "\n",
    "with open(os.path.join(output_dir, 'test_data.txt'), 'w', encoding='utf-8') as file:\n",
    "    file.write(tokenizer.convert_tokens_to_string(test_text))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "data_dir = 'data/raw'\n",
    "character_dialogues = {}\n",
    "current_character = None\n",
    "\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join(data_dir, filename), 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                # Check if the line contains the character's name (e.g., \"First Citizen:\")\n",
    "                if line.strip().endswith(\":\"):\n",
    "                    current_character = line.strip()\n",
    "                    if current_character not in character_dialogues:\n",
    "                        character_dialogues[current_character] = []\n",
    "                elif current_character:\n",
    "                    character_dialogues[current_character].append(line.strip())\n",
    "\n",
    "formatted_dialogues = []\n",
    "for character, dialogues in character_dialogues.items():\n",
    "    formatted_dialogues.append(character)\n",
    "    formatted_dialogues.extend(dialogues)\n",
    "\n",
    "with open(os.path.join(output_dir, 'formatted_dialogues.txt'), 'w', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(formatted_dialogues))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**You will end up with three different folders in the data (\"raw\", \"enhanced\" and \"processed\") where \"raw\" data refers to Kaggle, \"enhanced\" to the one processed over the input.txt file in Github, and \"processed\" reffering to the last method.**"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tf_gpu",
   "language": "python",
   "display_name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
